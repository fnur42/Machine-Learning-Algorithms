{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a180caa",
   "metadata": {
    "papermill": {
     "duration": 0.009229,
     "end_time": "2024-02-04T18:00:08.948014",
     "exception": false,
     "start_time": "2024-02-04T18:00:08.938785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine Learning with Python\n",
    "\n",
    "* Linear regression (least squares regression)\n",
    "* Logistic regression\n",
    "* Linear discriminant analysis\n",
    "* Decision trees\n",
    "* Naive Bayes (hem sÄ±nÄ±flandÄ±rma hem de regrasyon iÃ§in) / Bayes Teoremi\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Expectation Maximization (EM)\n",
    "* Support Vector Machines (SVM\n",
    "* Random Forests\n",
    "* Gradient Boosting Machines (GBM)\n",
    "* Gradient descent\n",
    "* Derin Ã–ÄŸrenme Modelleri (Yapay Sinir AÄŸlarÄ±)\n",
    "* KÃ¼meleme (K-Means, HiyerarÅŸik KÃ¼meleme, Gausian KarÄ±ÅŸÄ±m Modeli)\n",
    "* Maximum Likelihood/Gauss-Newton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a854d",
   "metadata": {
    "papermill": {
     "duration": 0.008383,
     "end_time": "2024-02-04T18:00:08.965102",
     "exception": false,
     "start_time": "2024-02-04T18:00:08.956719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "> K-En YakÄ±n KomÅŸular (KNN), hem sÄ±nÄ±flandÄ±rma hem de regresyon gÃ¶revleri iÃ§in kullanÄ±labilen basit bir denetimli makine Ã¶ÄŸrenimi algoritmasÄ±dÄ±r.Temel fikir, bir veri noktasÄ±nÄ±n tahmin edilmesinde, o noktaya en yakÄ±n komÅŸularÄ±nÄ±n etkisini kullanmaktÄ±r.\n",
    "\n",
    "> Algoritma Ã§alÄ±ÅŸma prensibi ÅŸu adÄ±mlarÄ± izler:\n",
    "\n",
    "* EÄŸitim veri setindeki tÃ¼m veri noktalarÄ±nÄ±n Ã¶zellik vektÃ¶rleri ve etiketleri kaydedilir.\n",
    "* Bir test veri noktasÄ± verildiÄŸinde, bu noktaya en yakÄ±n k komÅŸusu bulunur.\n",
    "* SÄ±nÄ±flandÄ±rma problemlerinde, bu k komÅŸunun etiketleri incelenir ve en sÄ±k tekrar eden etiket tahmin olarak verilir.\n",
    "* Regresyon problemlerinde, bu k komÅŸunun etiketlerinin ortalamasÄ± tahmin olarak verilir.\n",
    "\n",
    "> KNN algoritmasÄ±, yeni veri noktalarÄ±nÄ± tahmin etmek iÃ§in oldukÃ§a basit ve etkili bir yÃ¶ntemdir. Ancak, bÃ¼yÃ¼k veri setlerinde hesaplama yoÄŸunluÄŸu ve bellek kullanÄ±mÄ± gibi bazÄ± zorluklarla karÅŸÄ±laÅŸabilir.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38daf3c7",
   "metadata": {
    "papermill": {
     "duration": 0.008375,
     "end_time": "2024-02-04T18:00:08.982066",
     "exception": false,
     "start_time": "2024-02-04T18:00:08.973691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***AÅŸaÄŸÄ±daki Kod HazÄ±r Fonksiyon KullanÄ±lmadan YapÄ±lmÄ±ÅŸtÄ±r!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41559a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:00:09.001137Z",
     "iopub.status.busy": "2024-02-04T18:00:09.000443Z",
     "iopub.status.idle": "2024-02-04T18:00:10.283251Z",
     "shell.execute_reply": "2024-02-04T18:00:10.281969Z"
    },
    "papermill": {
     "duration": 1.294892,
     "end_time": "2024-02-04T18:00:10.285444",
     "exception": false,
     "start_time": "2024-02-04T18:00:08.990552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ä°ris veri setini yÃ¼kleme\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# EÄŸitim ve test setlerine ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# KNN sÄ±nÄ±fÄ±nÄ± tanÄ±mlama\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for i in range(len(X_test)):\n",
    "            distances = [self.euclidean_distance(X_test[i], x_train) for x_train in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[j] for j in k_indices]\n",
    "            most_common = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "            predictions.append(most_common)\n",
    "        return predictions\n",
    "\n",
    "# KNN modelini oluÅŸturma\n",
    "knn = KNN(k=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Modeli test seti Ã¼zerinde deÄŸerlendirme\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfdc0a",
   "metadata": {
    "papermill": {
     "duration": 0.008444,
     "end_time": "2024-02-04T18:00:10.302734",
     "exception": false,
     "start_time": "2024-02-04T18:00:10.294290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "> Lojistik regresyon, ikili baÄŸÄ±mlÄ± bir deÄŸiÅŸkeni modellemek iÃ§in lojistik bir iÅŸlev kullanan istatistiksel bir modeldir. Kategorik baÄŸÄ±mlÄ± bir deÄŸiÅŸkenin olasÄ±lÄ±ÄŸÄ±nÄ± tahmin etmek iÃ§in kullanÄ±lan denetimli bir Ã¶ÄŸrenme sÄ±nÄ±flandÄ±rma algoritmasÄ±dÄ±r.Logistic Regression, baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin aÄŸÄ±rlÄ±klarÄ±nÄ± ve etkilerini kullanarak, her bir sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ±nÄ± tahmin eder. Ancak, doÄŸrudan sÄ±nÄ±flarÄ±n tahmin edilmesi yerine, bir giriÅŸin her sÄ±nÄ±fa ait olma olasÄ±lÄ±ÄŸÄ± verilir. Bu olasÄ±lÄ±klar daha sonra bir eÅŸik deÄŸeri (threshold) kullanÄ±larak sÄ±nÄ±flara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.\n",
    "\n",
    "> Logistic Regression modeli, sigmoid fonksiyonu olarak da bilinen lojistik fonksiyon kullanÄ±larak oluÅŸturulur. Bu fonksiyon, sonsuz olan bir aralÄ±ktaki giriÅŸlerin deÄŸerini 0 ile 1 arasÄ±nda bir Ã§Ä±ktÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, bu da olasÄ±lÄ±k olarak yorumlanabilir. Logistic Regression algoritmasÄ±, parametre tahminlerini genellikle maksimum olabilirlik tahmini (maximum likelihood estimation) yÃ¶ntemiyle elde eder. Bu, veri setinin olasÄ±lÄ±ÄŸÄ±nÄ± maksimize etmek iÃ§in model parametrelerini ayarlamayÄ± iÃ§erir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af1cce",
   "metadata": {
    "papermill": {
     "duration": 0.008301,
     "end_time": "2024-02-04T18:00:10.319655",
     "exception": false,
     "start_time": "2024-02-04T18:00:10.311354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/dipayanbiswas/parkinsons-disease-speech-signal-features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e3976",
   "metadata": {
    "papermill": {
     "duration": 0.010237,
     "end_time": "2024-02-04T18:00:10.338887",
     "exception": false,
     "start_time": "2024-02-04T18:00:10.328650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***AÅŸaÄŸÄ±daki Kod HazÄ±r Fonksiyon KullanÄ±lmadan YapÄ±lmÄ±ÅŸtÄ±r!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c827778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:00:10.357948Z",
     "iopub.status.busy": "2024-02-04T18:00:10.357260Z",
     "iopub.status.idle": "2024-02-04T18:00:11.661732Z",
     "shell.execute_reply": "2024-02-04T18:00:11.660525Z"
    },
    "papermill": {
     "duration": 1.317728,
     "end_time": "2024-02-04T18:00:11.665252",
     "exception": false,
     "start_time": "2024-02-04T18:00:10.347524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 755)\n",
      "Accuracy: 0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('/kaggle/input/parkinsons-disease-speech-signal-features/pd_speech_features.csv')\n",
    "\n",
    "# Exploratory data analysis\n",
    "print(df.shape)\n",
    "\n",
    "# BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri tanÄ±mlama\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Veriyi eÄŸitim ve test setlerine ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verileri Ã¶lÃ§eklendirme\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Lojistik regresyon modeli oluÅŸturma\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self.sigmoid(model)\n",
    "            \n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return y_predicted_cls\n",
    "\n",
    "# Modeli eÄŸitme\n",
    "model = LogisticRegression(learning_rate=0.1, n_iterations=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Modeli deÄŸerlendirme\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f8a96",
   "metadata": {
    "papermill": {
     "duration": 0.018271,
     "end_time": "2024-02-04T18:00:11.702695",
     "exception": false,
     "start_time": "2024-02-04T18:00:11.684424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Maximum Likelihood/Gauss-Newton\n",
    "\n",
    "> Maximum Likelihood ve Gauss-Newton, parametre tahmininde kullanÄ±lan iki farklÄ± yÃ¶ntemdir.\n",
    "\n",
    "**1. Maximum Likelihood (MLE - Maximum Likelihood Estimation):** \n",
    "\n",
    "> Bu yÃ¶ntem, parametre tahminindeki bir olasÄ±lÄ±k odaklÄ± yaklaÅŸÄ±mdÄ±r. Bir model belirlendiÄŸinde, MLE, gÃ¶zlemlenen veri setinin bu modele en uygun parametre deÄŸerlerini bulmaya Ã§alÄ±ÅŸÄ±r. Bu parametreler, veri setinin olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ±n maksimum olasÄ±lÄ±ÄŸÄ±nÄ± saÄŸlamak iÃ§in tahmin edilir.\n",
    "\n",
    "**2. Gauss-Newton:** \n",
    "\n",
    "> Bu yÃ¶ntem, Ã¶zellikle doÄŸrusal olmayan regresyon modellerinde kullanÄ±lan bir optimizasyon yÃ¶ntemidir. Bir tahmin modelinin parametrelerini gÃ¼ncellemek iÃ§in kullanÄ±lÄ±r. Gauss-Newton yÃ¶ntemi, hedef fonksiyonunun (genellikle ortalama kareler hatasÄ±) birinci ve ikinci tÃ¼revlerini kullanarak iteratif olarak parametreleri gÃ¼nceller. Bu yÃ¶ntem, tahmin edilen parametrelerin gerÃ§ek deÄŸerlere yakÄ±nsamasÄ±nÄ± saÄŸlamak iÃ§in kullanÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d41c34",
   "metadata": {
    "papermill": {
     "duration": 0.018185,
     "end_time": "2024-02-04T18:00:11.739581",
     "exception": false,
     "start_time": "2024-02-04T18:00:11.721396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**AÅŸaÄŸÄ±daki Maximum Likelihood/Gauss Newton Kodunda KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/abhia1999/chronic-kidney-disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355c6c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:00:11.778808Z",
     "iopub.status.busy": "2024-02-04T18:00:11.778308Z",
     "iopub.status.idle": "2024-02-04T18:00:11.826047Z",
     "shell.execute_reply": "2024-02-04T18:00:11.825056Z"
    },
    "papermill": {
     "duration": 0.070054,
     "end_time": "2024-02-04T18:00:11.828300",
     "exception": false,
     "start_time": "2024-02-04T18:00:11.758246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Likelihood MSE: 0.0798591010435056\n",
      "Gauss-Newton MSE: 0.07985910113886487\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Veri setini yÃ¼kleme\n",
    "df = pd.read_csv('/kaggle/input/chronic-kidney-disease/new_model.csv')\n",
    "\n",
    "# Ã–zellikler ve hedef deÄŸiÅŸkeni seÃ§me\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# EÄŸitim ve test setlerini ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Maximum Likelihood yÃ¶ntemi ile model oluÅŸturma\n",
    "def log_likelihood(params, X, y):\n",
    "    a = params\n",
    "    y_pred = np.dot(X, a)\n",
    "    residuals = y - y_pred\n",
    "    likelihood = -np.sum(norm.logpdf(residuals))\n",
    "    return likelihood\n",
    "\n",
    "def log_likelihood_gradient(params, X, y):\n",
    "    a = params\n",
    "    y_pred = np.dot(X, a)\n",
    "    residuals = y - y_pred\n",
    "    gradient = -np.dot(X.T, residuals)  # Gradient hesaplama hatasÄ± dÃ¼zeltildi\n",
    "    return gradient\n",
    "\n",
    "params_init = np.random.rand(X_train.shape[1])\n",
    "\n",
    "result_ml = minimize(log_likelihood, params_init, args=(X_train, y_train), method='BFGS', jac=log_likelihood_gradient)\n",
    "params_ml = result_ml.x\n",
    "\n",
    "# Gauss-Newton yÃ¶ntemi ile model oluÅŸturma\n",
    "def gauss_newton(params, X, y):\n",
    "    a = params\n",
    "    y_pred = np.dot(X, a)\n",
    "    residuals = y - y_pred\n",
    "    jacobian = -X  # Jacobian hesaplama hatasÄ± dÃ¼zeltildi\n",
    "    hessian = np.dot(jacobian.T, jacobian)\n",
    "    gradient = np.dot(jacobian.T, residuals)\n",
    "    params_new = params - np.linalg.solve(hessian, gradient)\n",
    "    return params_new\n",
    "\n",
    "params_gn = gauss_newton(params_init, X_train, y_train)\n",
    "\n",
    "# Model performansÄ±nÄ± deÄŸerlendirme\n",
    "def evaluate_model(params, X, y):\n",
    "    y_pred = np.dot(X, params)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return mse\n",
    "\n",
    "mse_ml = evaluate_model(params_ml, X_test, y_test)\n",
    "mse_gn = evaluate_model(params_gn, X_test, y_test)\n",
    "\n",
    "print(\"Maximum Likelihood MSE:\", mse_ml)\n",
    "print(\"Gauss-Newton MSE:\", mse_gn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7faa3",
   "metadata": {
    "papermill": {
     "duration": 0.008637,
     "end_time": "2024-02-04T18:00:11.846040",
     "exception": false,
     "start_time": "2024-02-04T18:00:11.837403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "> Bir destek vektÃ¶r makinesi (SVM), hem sÄ±nÄ±flandÄ±rma hem de regresyon gÃ¶revleri iÃ§in kullanÄ±labilen denetimli bir makine Ã¶ÄŸrenimi algoritmasÄ±dÄ±r. Ä°ki sÄ±nÄ±fÄ±n Ã¶rnekleri arasÄ±ndaki en bÃ¼yÃ¼k farkla farklÄ± sÄ±nÄ±flarÄ± ayÄ±rmak iÃ§in bir hiper dÃ¼zlem kullanÄ±r. Bu, modelin genelleme yeteneÄŸini geliÅŸtirmeye yardÄ±mcÄ± olur.\n",
    "\n",
    "> SVM'nin Ã§alÄ±ÅŸma prensibi, veri noktalarÄ±nÄ± sÄ±nÄ±flar arasÄ±nda bir hiperdÃ¼zlemle (veya dÃ¼zlemle) en iyi ÅŸekilde ayÄ±rmaya Ã§alÄ±ÅŸÄ±rken, bu hiperdÃ¼zlemi belirlerken maksimum marjinal ayÄ±rma ilkesini kullanÄ±r. Marjin, sÄ±nÄ±flar arasÄ±ndaki en yakÄ±n veri noktalarÄ± ile hiperdÃ¼zlem arasÄ±ndaki mesafedir. SVM, bu marjini maksimize eden hiperdÃ¼zlemi seÃ§er, bÃ¶ylece yeni veri noktalarÄ± sÄ±nÄ±flandÄ±rÄ±lÄ±rken daha iyi genelleme yapabilir.\n",
    "> \n",
    "> SVM'nin avantajlarÄ± arasÄ±nda yÃ¼ksek boyutlu veri setleri Ã¼zerinde etkili performans, Ã§eÅŸitli kernel fonksiyonlarÄ±nÄ± kullanabilme esnekliÄŸi ve overfitting'e karÅŸÄ± direnÃ§ gibi Ã¶zellikler bulunur. SVM ayrÄ±ca doÄŸrusal olmayan veri setleri Ã¼zerinde de iyi performans gÃ¶sterebilir, bunun iÃ§in Ã§eÅŸitli kernel fonksiyonlarÄ± kullanÄ±lÄ±r.\n",
    ">\n",
    "> SVM'nin bir diÄŸer Ã¶nemli Ã¶zelliÄŸi, destek vektÃ¶rleri kullanarak modeli Ã¶zetlemesidir. Destek vektÃ¶rleri, sÄ±nÄ±flar arasÄ±ndaki marjinal ayÄ±rÄ±cÄ± hiperdÃ¼zleme en yakÄ±n olan veri noktalarÄ±dÄ±r. Bu destek vektÃ¶rleri, SVM modelinin optimum hiperdÃ¼zlemi belirlemesinde kilit rol oynar.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72edf1af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:00:11.865008Z",
     "iopub.status.busy": "2024-02-04T18:00:11.864748Z",
     "iopub.status.idle": "2024-02-04T18:01:09.877092Z",
     "shell.execute_reply": "2024-02-04T18:01:09.876128Z"
    },
    "papermill": {
     "duration": 58.032492,
     "end_time": "2024-02-04T18:01:09.887615",
     "exception": false,
     "start_time": "2024-02-04T18:00:11.855123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
      "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
      "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
      "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
      "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
      "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
      "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
      "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
      "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
      "0       0.0       0.0       0.0                           1  \n",
      "1    1000.0       0.0    2000.0                           1  \n",
      "2    1000.0    1000.0    5000.0                           0  \n",
      "3    1100.0    1069.0    1000.0                           0  \n",
      "4    9000.0     689.0     679.0                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Model DoÄŸruluÄŸu: 0.8152\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "veri = pd.read_csv(\"/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\")\n",
    "\n",
    "print(veri.head())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = veri.drop(\"default.payment.next.month\", axis=1)\n",
    "y = veri[\"default.payment.next.month\"]\n",
    "\n",
    "X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_egitim = scaler.fit_transform(X_egitim)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_modeli = SVC(kernel='linear')\n",
    "svm_modeli.fit(X_egitim, y_egitim)\n",
    "\n",
    "dogruluk = svm_modeli.score(X_test, y_test)\n",
    "print(\"Model DoÄŸruluÄŸu:\", dogruluk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f11a10",
   "metadata": {
    "papermill": {
     "duration": 0.008718,
     "end_time": "2024-02-04T18:01:09.905356",
     "exception": false,
     "start_time": "2024-02-04T18:01:09.896638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "> Rastgele orman, eÄŸitim sÄ±rasÄ±nda Ã§ok sayÄ±da karar aÄŸacÄ± oluÅŸturarak ve tek tek aÄŸaÃ§larÄ±n sÄ±nÄ±flarÄ±nÄ±n modu olan sÄ±nÄ±fÄ± Ã§Ä±kararak Ã§alÄ±ÅŸan, topluluk denetimli bir makine Ã¶ÄŸrenimi algoritmasÄ±dÄ±r. Verilerin bÃ¼yÃ¼k bir kÄ±smÄ± eksik olduÄŸunda doÄŸruluÄŸu korur.\n",
    "\n",
    "> Random Forest algoritmasÄ±, birden fazla karar aÄŸacÄ±nÄ±n (decision tree) oluÅŸturulmasÄ±nÄ± iÃ§erir. Her karar aÄŸacÄ±, rastgele Ã¶rneklerle (bootstrap sampling) ve rastgele Ã¶zelliklerle (feature sampling) eÄŸitilir. Bu ÅŸekilde, her bir karar aÄŸacÄ± farklÄ± bir alt kÃ¼me veri ve Ã¶zellik kÃ¼mesi Ã¼zerinde eÄŸitilir, bu da modele Ã§eÅŸitlilik katar.\n",
    "> \n",
    "> SÄ±nÄ±flandÄ±rma problemleri iÃ§in, Random Forest karar aÄŸaÃ§larÄ± genellikle Ã§oÄŸunluk oyu (majority vote) prensibiyle birleÅŸtirilir. Yani, her karar aÄŸacÄ±nÄ±n tahmin ettiÄŸi sÄ±nÄ±f deÄŸerlerinin ortalamasÄ± alÄ±narak final tahmin yapÄ±lÄ±r. Regresyon problemleri iÃ§in ise karar aÄŸaÃ§larÄ±nÄ±n tahmin ettiÄŸi deÄŸerlerin ortalamasÄ± alÄ±nÄ±r.\n",
    "> \n",
    "> Random Forest'Ä±n avantajlarÄ± arasÄ±nda yÃ¼ksek doÄŸruluk, overfitting'e karÅŸÄ± direnÃ§, farklÄ± Ã¶zellik tÃ¼rlerini (kategorik, sayÄ±sal) bir arada kullanabilme yeteneÄŸi ve dengesiz veri setlerinde etkili performans gÃ¶sterme kabiliyeti bulunur.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a144ee38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:09.925108Z",
     "iopub.status.busy": "2024-02-04T18:01:09.924800Z",
     "iopub.status.idle": "2024-02-04T18:01:10.381082Z",
     "shell.execute_reply": "2024-02-04T18:01:10.380054Z"
    },
    "papermill": {
     "duration": 0.468546,
     "end_time": "2024-02-04T18:01:10.383047",
     "exception": false,
     "start_time": "2024-02-04T18:01:09.914501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n",
      "Accuracy: 0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load data\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\n",
    "\n",
    "# Exploratory data analysis \n",
    "print(df.shape)\n",
    "print(df.describe())\n",
    "\n",
    "# Preprocess data\n",
    "X = df.drop('Outcome', axis=1) \n",
    "y = df['Outcome']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model \n",
    "y_pred = rf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3926f0d",
   "metadata": {
    "papermill": {
     "duration": 0.009362,
     "end_time": "2024-02-04T18:01:10.402155",
     "exception": false,
     "start_time": "2024-02-04T18:01:10.392793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Neural Network\n",
    "\n",
    "> Yapay Sinir AÄŸlarÄ± (Neural Networks), beyin biyolojisinden ilham alarak tasarlanmÄ±ÅŸ bir makine Ã¶ÄŸrenimi ve yapay zeka yÃ¶ntemidir. Bir sinir aÄŸÄ±, nÃ¶ron adÄ± verilen basit birimlerin birbirine baÄŸlÄ± olduÄŸu bir yapÄ±dÄ±r. Her bir nÃ¶ron, girdi verilerini alÄ±r, bu verileri aÄŸÄ±rlÄ±klarla Ã§arparak toplar, bir aktivasyon fonksiyonuna sokar ve Ã§Ä±ktÄ±yÄ± Ã¼retir.\n",
    "\n",
    "> Yapay sinir aÄŸlarÄ±, genellikle bir girdi katmanÄ±, bir veya daha fazla gizli katman ve bir Ã§Ä±ktÄ± katmanÄ±ndan oluÅŸur. Katmanlar arasÄ±ndaki baÄŸlantÄ±lar, aÄŸÄ±rlÄ±klar olarak adlandÄ±rÄ±lan parametrelerle belirlenir. EÄŸitim sÃ¼recinde, sinir aÄŸÄ±, girdi verileriyle beslenir ve belirlenen hedef Ã§Ä±ktÄ±ya yaklaÅŸmak iÃ§in aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellemek iÃ§in geriye doÄŸru yayÄ±lÄ±m algoritmasÄ± kullanÄ±r.\n",
    "> \n",
    "> Yapay Sinir AÄŸlarÄ±, geniÅŸ bir uygulama yelpazesine sahiptir ve sÄ±nÄ±flandÄ±rma, regresyon, kÃ¼melenme, desen tanÄ±ma, doÄŸal dil iÅŸleme ve oyun yapay zekasÄ± gibi birÃ§ok alanda kullanÄ±lÄ±rlar. Derin Ã–ÄŸrenme (Deep Learning) adÄ± verilen ve Ã§ok katmanlÄ± sinir aÄŸlarÄ±nÄ±n kullanÄ±ldÄ±ÄŸÄ± bir alt dalÄ±yla birlikte, Ã¶zellikle bÃ¼yÃ¼k ve karmaÅŸÄ±k veri setleri Ã¼zerinde baÅŸarÄ±lÄ± sonuÃ§lar elde edilmiÅŸtir.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8bc1648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:10.422445Z",
     "iopub.status.busy": "2024-02-04T18:01:10.421822Z",
     "iopub.status.idle": "2024-02-04T18:01:28.056199Z",
     "shell.execute_reply": "2024-02-04T18:01:28.055148Z"
    },
    "papermill": {
     "duration": 17.646732,
     "end_time": "2024-02-04T18:01:28.058195",
     "exception": false,
     "start_time": "2024-02-04T18:01:10.411463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:01:12.321533: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-04 18:01:12.321633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-04 18:01:12.479169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 14)\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   69    1   0       160   234    1        2      131      0      0.1      1   \n",
      "1   69    0   0       140   239    0        0      151      0      1.8      0   \n",
      "2   66    0   0       150   226    0        0      114      0      2.6      2   \n",
      "3   65    1   0       138   282    1        2      174      0      1.4      1   \n",
      "4   64    1   0       110   211    0        2      144      1      1.8      1   \n",
      "\n",
      "   ca  thal  condition  \n",
      "0   1     0          0  \n",
      "1   2     0          0  \n",
      "2   0     0          0  \n",
      "3   1     0          1  \n",
      "4   0     0          0  \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707069685.812987      71 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 4ms/step - loss: 0.7905 - accuracy: 0.3502\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.4388\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.5316\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.6034\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6329\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6540\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6793\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.7089\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7342\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7511\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7679\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7806\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7806\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7679\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7722\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7764\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7890\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7975\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.8017\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8017\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8059\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8143\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8270\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8270\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8312\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8312\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8312\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8354\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8312\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8354\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8354\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8439\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8481\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8481\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8523\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8565\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8608\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8608\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8692\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8692\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8692\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8692\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8734\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8734\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8734\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8734\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8734\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8734\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8819\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8819\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7500\n",
      "Test Loss: 0.4673685133457184\n",
      "Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('/kaggle/input/heart-disease-cleveland-uci/heart_cleveland_upload.csv')\n",
    "\n",
    "# Exploratory data analysis\n",
    "print(df.shape) \n",
    "print(df.head())\n",
    "\n",
    "# Preprocess data\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Custom neural network implementation\n",
    "model = Sequential()\n",
    "model.add(Dense(units=16, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "# Train model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "# Model evaluation\n",
    "#print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e86f10",
   "metadata": {
    "papermill": {
     "duration": 0.021662,
     "end_time": "2024-02-04T18:01:28.101561",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.079899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "> Ã‡oklu DoÄŸrusal Regresyon (Multiple Linear Regression), bir baÄŸÄ±mlÄ± deÄŸiÅŸkenin birden fazla baÄŸÄ±msÄ±z deÄŸiÅŸken tarafÄ±ndan aÃ§Ä±klanmaya Ã§alÄ±ÅŸÄ±ldÄ±ÄŸÄ± bir regresyon analizi yÃ¶ntemidir. Ã‡oklu doÄŸrusal regresyon, baÄŸÄ±mlÄ± deÄŸiÅŸkenin tahmin edilmesinde kullanÄ±lan baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin doÄŸrusal bir kombinasyonunu ifade eden bir denklemi kullanÄ±r.\n",
    "\n",
    "> Bu regresyon denklemi, baÄŸÄ±mlÄ± deÄŸiÅŸkenin beklenen deÄŸerini, baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin katsayÄ±larÄ± ve bir sabitin bir kombinasyonu olarak ifade eder.Tahminlerin doÄŸruluÄŸu, modelin uyumunun derecesi ve baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin baÄŸÄ±mlÄ± deÄŸiÅŸken Ã¼zerindeki etkisi gibi faktÃ¶rlere baÄŸlÄ±dÄ±r.\n",
    "\n",
    "> MSE (Mean Squared Error), bir regresyon modelinin tahminlerinin gerÃ§ek deÄŸerlerden ne kadar uzak olduÄŸunu Ã¶lÃ§en bir performans metriÄŸidir.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033c3c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:28.146476Z",
     "iopub.status.busy": "2024-02-04T18:01:28.145720Z",
     "iopub.status.idle": "2024-02-04T18:01:28.183594Z",
     "shell.execute_reply": "2024-02-04T18:01:28.182377Z"
    },
    "papermill": {
     "duration": 0.063239,
     "end_time": "2024-02-04T18:01:28.186238",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.122999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.39002514396395477\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Veri setini yÃ¼kleme\n",
    "df = pd.read_csv(\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\n",
    "\n",
    "# BaÄŸÄ±mlÄ± deÄŸiÅŸken (y) ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) olarak ayÄ±rma\n",
    "# Preprocess data  \n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Veriyi eÄŸitim ve test setlerine ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear regresyon modelini oluÅŸturma ve eÄŸitme\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Modeli test seti Ã¼zerinde deÄŸerlendirme\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a09cc",
   "metadata": {
    "papermill": {
     "duration": 0.021641,
     "end_time": "2024-02-04T18:01:28.231260",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.209619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NonLinear Regression\n",
    "\n",
    "> Nonlinear Regression, baÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkinin doÄŸrusal olmadÄ±ÄŸÄ± durumlar iÃ§in kullanÄ±lan bir regresyon analiz yÃ¶ntemidir. Bu yÃ¶ntem, doÄŸrusal olmayan bir modelin veriye uyarlanmasÄ± iÃ§in kullanÄ±lÄ±r. Genellikle, bir polinom ya da baÅŸka bir matematiksel fonksiyon kullanÄ±larak bu iliÅŸki modellenir. Bu yÃ¶ntem, veri setindeki karmaÅŸÄ±k iliÅŸkileri modellemek iÃ§in kullanÄ±lÄ±r ve doÄŸrusal regresyonun yetersiz kaldÄ±ÄŸÄ± durumlarda tercih edilir.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/harrywang/wine-dataset-for-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b2427a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:28.276426Z",
     "iopub.status.busy": "2024-02-04T18:01:28.275568Z",
     "iopub.status.idle": "2024-02-04T18:01:28.296817Z",
     "shell.execute_reply": "2024-02-04T18:01:28.295822Z"
    },
    "papermill": {
     "duration": 0.046303,
     "end_time": "2024-02-04T18:01:28.298983",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.252680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ortalama Kareler HatasÄ± (MSE): 143587.95354817758\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Veri setini yÃ¼kleme\n",
    "data = pd.read_csv(\"/kaggle/input/wine-dataset-for-clustering/wine-clustering.csv\")\n",
    "\n",
    "# BaÄŸÄ±mlÄ± deÄŸiÅŸken (y) ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) olarak ayÄ±rma\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Veriyi eÄŸitim ve test setlerine ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# DoÄŸrusal olmayan regresyon modelini oluÅŸturma ve eÄŸitme\n",
    "model = SVR()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Modeli test seti Ã¼zerinde deÄŸerlendirme\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Ortalama Kareler HatasÄ± (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e7d83",
   "metadata": {
    "papermill": {
     "duration": 0.021259,
     "end_time": "2024-02-04T18:01:28.343212",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.321953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decision trees\n",
    "\n",
    "> Karar aÄŸaÃ§larÄ±, birÃ§ok makine Ã¶ÄŸrenimi algoritmasÄ±ndan biridir ve sÄ±nÄ±flandÄ±rma ve regresyon problemlerinde kullanÄ±lÄ±r. Bir karar aÄŸacÄ±, bir veri kÃ¼mesindeki Ã¶zelliklere dayalÄ± olarak bir dizi karar dÃ¼ÄŸÃ¼mÃ¼ ve sonuÃ§larÄ± olan yaprak dÃ¼ÄŸÃ¼mleri iÃ§eren bir aÄŸaÃ§ yapÄ±sÄ±dÄ±r. Karar aÄŸaÃ§larÄ±, veri kÃ¼mesini belirli Ã¶zelliklere gÃ¶re bÃ¶lerek ve her dÃ¼ÄŸÃ¼mdeki en uygun bÃ¶lÃ¼nmeyi seÃ§erek veri kÃ¼mesini sÄ±nÄ±flandÄ±rmak veya regresyon yapmak iÃ§in kullanÄ±lÄ±r.\n",
    "\n",
    "> Karar aÄŸaÃ§larÄ±, verileri anlamak ve yorumlamak kolay olduÄŸu iÃ§in popÃ¼lerdir. AyrÄ±ca, karmaÅŸÄ±k iliÅŸkileri modelleyebilirler ve genellikle diÄŸer makine Ã¶ÄŸrenimi algoritmalarÄ±ndan daha hÄ±zlÄ± eÄŸitim sÃ¼relerine sahiptirler. Karar aÄŸaÃ§larÄ±, sÄ±nÄ±flandÄ±rma ve regresyon problemleri iÃ§in geniÅŸ bir uygulama yelpazesine sahiptir.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/heptapod/uci-ml-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7a6824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:28.388661Z",
     "iopub.status.busy": "2024-02-04T18:01:28.388342Z",
     "iopub.status.idle": "2024-02-04T18:01:28.414586Z",
     "shell.execute_reply": "2024-02-04T18:01:28.413575Z"
    },
    "papermill": {
     "duration": 0.051102,
     "end_time": "2024-02-04T18:01:28.416835",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.365733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8811881188118812\n",
      "[[89  5]\n",
      " [ 7  0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/uci-ml-datasets/hou_all.csv')\n",
    "\n",
    "X = df.drop('0', axis=1)\n",
    "y = df['0']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Degerlendir ve Tahmin Et\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Dogruluk degeri dondur\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6cd61",
   "metadata": {
    "papermill": {
     "duration": 0.021605,
     "end_time": "2024-02-04T18:01:28.461423",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.439818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Naive Bayes / Bayes Teoremi\n",
    "\n",
    "> Bayes Teoremi, bir olayÄ±n gerÃ§ekleÅŸme olasÄ±lÄ±ÄŸÄ±nÄ±, bu olayÄ±n meydana gelmesine iliÅŸkin kanÄ±tlara dayanarak gÃ¼ncellemeyi saÄŸlayan bir formÃ¼l olarak tanÄ±mlanÄ±r.Naive Bayes, Bayes Teoremi'nin bir uygulamasÄ±dÄ±r ve sÄ±nÄ±flandÄ±rma problemlerinde sÄ±klÄ±kla kullanÄ±lÄ±r. Bu algoritma, belirli bir Ã¶rneÄŸin bir sÄ±nÄ±fa ait olma olasÄ±lÄ±ÄŸÄ±nÄ±, Ã¶zniteliklerin deÄŸerleri verildiÄŸinde Bayes Teoremi'ni kullanarak hesaplar. Ã–znitelikler arasÄ±nda baÄŸÄ±msÄ±zlÄ±k varsayÄ±mÄ± yapar, yani Ã¶znitelikler arasÄ±ndaki iliÅŸkileri gÃ¶z ardÄ± eder\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/piyushrumao/malware-executable-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35757808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:28.506063Z",
     "iopub.status.busy": "2024-02-04T18:01:28.505747Z",
     "iopub.status.idle": "2024-02-04T18:01:28.588001Z",
     "shell.execute_reply": "2024-02-04T18:01:28.586972Z"
    },
    "papermill": {
     "duration": 0.106888,
     "end_time": "2024-02-04T18:01:28.590054",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.483166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9866666666666667\n",
      "[[64  0]\n",
      " [ 1 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/malware-executable-detection/uci_malware_detection.csv')\n",
    "\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#Naive Bayes SÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± BaÅŸlat\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3112c42",
   "metadata": {
    "papermill": {
     "duration": 0.022891,
     "end_time": "2024-02-04T18:01:28.634728",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.611837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gradient Descent Algorithm\n",
    "\n",
    "> Gradient descent (gradyan iniÅŸi), bir fonksiyonun minimumunu bulmak iÃ§in kullanÄ±lan bir optimizasyon algoritmasÄ±dÄ±r. Algoritma, mevcut konumda fonksiyonun gradyanÄ± (tÃ¼revi) ile doÄŸrudan ters yÃ¶nde hareket ederek minimuma doÄŸru ilerler. Bu iÅŸlem, gradyan vektÃ¶rÃ¼nÃ¼n negatifine doÄŸru kÃ¼Ã§Ã¼k adÄ±mlarla yapÄ±lÄ±r, bÃ¶ylece fonksiyon minimuma yaklaÅŸÄ±r. Gradient descent, makine Ã¶ÄŸrenmesinde model parametrelerini ayarlamak iÃ§in sÄ±kÃ§a kullanÄ±lan bir optimizasyon tekniÄŸidir.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/ritesaluja/bank-note-authentication-uci-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5786b5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:28.679867Z",
     "iopub.status.busy": "2024-02-04T18:01:28.679519Z",
     "iopub.status.idle": "2024-02-04T18:01:28.709958Z",
     "shell.execute_reply": "2024-02-04T18:01:28.709012Z"
    },
    "papermill": {
     "duration": 0.055602,
     "end_time": "2024-02-04T18:01:28.712186",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.656584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       148\n",
      "           1       0.97      0.97      0.97       127\n",
      "\n",
      "    accuracy                           0.97       275\n",
      "   macro avg       0.97      0.97      0.97       275\n",
      "weighted avg       0.97      0.97      0.97       275\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/bank-note-authentication-uci-data/BankNote_Authentication.csv')\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Descent SÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± BaÅŸlat\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2a70c",
   "metadata": {
    "papermill": {
     "duration": 0.02185,
     "end_time": "2024-02-04T18:01:28.757088",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.735238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gradient Boosting Machines (GBM)\n",
    "\n",
    "> Gradient Boosting Machines (GBM), genellikle karar aÄŸaÃ§larÄ±nÄ± bir araya getirerek gÃ¼Ã§lÃ¼ bir tahmin modeli oluÅŸturan bir makine Ã¶ÄŸrenmesi tekniÄŸidir. GBM, gradyan descent algoritmasÄ±nÄ± kullanarak aÄŸaÃ§larÄ± bir araya getirir. Her aÄŸaÃ§, Ã¶nceki aÄŸaÃ§larÄ±n hatalarÄ±nÄ± dÃ¼zeltmek iÃ§in eÄŸitilir.Bu sÃ¼reÃ§, hata azaldÄ±kÃ§a yeni aÄŸaÃ§lar ekleyerek devam eder.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/biomechanical-features-of-orthopedic-patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0aa94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:28.802174Z",
     "iopub.status.busy": "2024-02-04T18:01:28.801563Z",
     "iopub.status.idle": "2024-02-04T18:01:28.930107Z",
     "shell.execute_reply": "2024-02-04T18:01:28.929072Z"
    },
    "papermill": {
     "duration": 0.153257,
     "end_time": "2024-02-04T18:01:28.932077",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.778820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.7580645161290323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Gradient Boosting Classifier BaÅŸlat\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Model accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c383fcb",
   "metadata": {
    "papermill": {
     "duration": 0.021515,
     "end_time": "2024-02-04T18:01:28.975867",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.954352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KÃ¼meleme (K-Means, HiyerarÅŸik KÃ¼meleme, Gausian KarÄ±ÅŸÄ±m Modeli)\n",
    "\n",
    "> KÃ¼meleme, bir veri kÃ¼mesindeki benzer Ã¶rnekleri gruplara ayÄ±rma iÅŸlemidir. KÃ¼meleme algoritmalarÄ±, veri noktalarÄ±nÄ± benzerliklerine gÃ¶re gruplandÄ±rmak iÃ§in kullanÄ±lÄ±r ve veri setindeki doÄŸal yapÄ±yÄ± tanÄ±mlamak ve keÅŸfetmek iÃ§in kullanÄ±lÄ±r.\n",
    "\n",
    "**1. K-Means KÃ¼meleme:**\n",
    "\n",
    "> K-Means kÃ¼meleme, veri noktalarÄ±nÄ± belirli sayÄ±da kÃ¼me veya k-merkezine gÃ¶re gruplandÄ±rÄ±r.\n",
    "> Algoritma, Ã¶nceden belirlenmiÅŸ k sayÄ±sÄ±nda kÃ¼me merkezlerini rastgele yerleÅŸtirir ve veri noktalarÄ±nÄ± bu merkezlere gÃ¶re gruplandÄ±rÄ±r.\n",
    "> ArdÄ±ndan, kÃ¼me merkezleri tekrar hesaplanÄ±r ve veri noktalarÄ± bu yeni merkezlere gÃ¶re yeniden gruplandÄ±rÄ±lÄ±r.\n",
    "> Bu iÅŸlem, kÃ¼me merkezlerinin hareket etmeyene kadar veya belirli bir iterasyon sayÄ±sÄ±na ulaÅŸÄ±lana kadar tekrarlanÄ±r.\n",
    "\n",
    "**2. HiyerarÅŸik KÃ¼meleme:**\n",
    "\n",
    "> HiyerarÅŸik kÃ¼meleme, veri noktalarÄ±nÄ± bir aÄŸaÃ§ yapÄ±sÄ± iÃ§inde hiyerarÅŸik olarak gruplandÄ±rÄ±r.\n",
    "> Bu algoritma, agglomeratif (birleÅŸtirici) ve bÃ¶lÃ¼cÃ¼ (ayÄ±rÄ±cÄ±) olmak Ã¼zere iki temel yaklaÅŸÄ±ma sahiptir.\n",
    "> Agglomeratif yÃ¶ntemde, her veri noktasÄ± bir kÃ¼me olarak baÅŸlar ve en yakÄ±n iki kÃ¼me birleÅŸtirilir.\n",
    "> BÃ¶lÃ¼cÃ¼ yÃ¶ntemde, tÃ¼m veri noktalarÄ± tek bir kÃ¼me olarak baÅŸlar ve her adÄ±mda kÃ¼me bÃ¶lÃ¼nÃ¼r.\n",
    "> Bu iÅŸlem, bir kÃ¼meleme aÄŸacÄ± oluÅŸturulana kadar veya belirli bir kÃ¼me sayÄ±sÄ±na ulaÅŸÄ±lana kadar devam eder.\n",
    "\n",
    "**3. Gauss KarÄ±ÅŸÄ±m Modeli (Gaussian Mixture Model - GMM):**\n",
    "\n",
    "> Gauss KarÄ±ÅŸÄ±m Modeli, veri noktalarÄ±nÄ± bir veya daha fazla Gauss daÄŸÄ±lÄ±mÄ±nÄ±n bir kombinasyonu olarak modellemek iÃ§in kullanÄ±lÄ±r.\n",
    "> GMM, her biri bir merkez ve bir kovaryans matrisine sahip olan bir dizi Gauss daÄŸÄ±lÄ±mÄ±ndan oluÅŸur.\n",
    "> GMM, veri noktalarÄ±nÄ± bu Gauss daÄŸÄ±lÄ±mlarÄ±na gÃ¶re en iyi uyacak ÅŸekilde gruplandÄ±rÄ±r.\n",
    "> Bu algoritma, verinin karmaÅŸÄ±k yapÄ±sÄ±nÄ± modellemek ve belirli bir veri setindeki farklÄ± bileÅŸenlerin katkÄ±sÄ±nÄ± anlamak iÃ§in kullanÄ±lÄ±r.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/sansuthi/dry-bean-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8b3b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:29.020586Z",
     "iopub.status.busy": "2024-02-04T18:01:29.020275Z",
     "iopub.status.idle": "2024-02-04T18:01:33.314920Z",
     "shell.execute_reply": "2024-02-04T18:01:33.313709Z"
    },
    "papermill": {
     "duration": 4.31959,
     "end_time": "2024-02-04T18:01:33.317224",
     "exception": false,
     "start_time": "2024-02-04T18:01:28.997634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Silhouette Score: 0.5449746269258475\n",
      "HiyerarÅŸik KÃ¼meleme Silhouette Score: 0.5294249957531247\n",
      "Gausian KarÄ±ÅŸÄ±m Modeli Silhouette Score: 0.13702610074964017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Veri setini yÃ¼kleme ve Ã¶n iÅŸleme\n",
    "df = pd.read_csv('/kaggle/input/dry-bean-dataset/Dry_Bean.csv')\n",
    "\n",
    "# BaÄŸÄ±mlÄ± deÄŸiÅŸken (y) ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) olarak ayÄ±rma\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Veri setini train ve test olarak ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# K-Means KÃ¼meleme\n",
    "kmeans = KMeans(n_clusters=5) #5 parÃ§aya ayrÄ±lÄ±r\n",
    "kmeans.fit(X_train) \n",
    "kmeans_labels = kmeans.predict(X_test)\n",
    "kmeans_silhouette_score = silhouette_score(X_test, kmeans_labels)\n",
    "\n",
    "# HiyerarÅŸik KÃ¼meleme\n",
    "hierarchical = AgglomerativeClustering(n_clusters=5)\n",
    "hierarchical_labels = hierarchical.fit_predict(X_test)\n",
    "hierarchical_silhouette_score = silhouette_score(X_test, hierarchical_labels)\n",
    "\n",
    "# Gausian KarÄ±ÅŸÄ±m Modeli\n",
    "gmm = GaussianMixture(n_components=5)\n",
    "gmm.fit(X_train)\n",
    "gmm_labels = gmm.predict(X_test)\n",
    "gmm_silhouette_score = silhouette_score(X_test, gmm_labels)\n",
    "\n",
    "# SonuÃ§larÄ± deÄŸerlendirme\n",
    "print(\"K-Means Silhouette Score:\", kmeans_silhouette_score)\n",
    "print(\"HiyerarÅŸik KÃ¼meleme Silhouette Score:\", hierarchical_silhouette_score)\n",
    "print(\"Gausian KarÄ±ÅŸÄ±m Modeli Silhouette Score:\", gmm_silhouette_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cffa2c",
   "metadata": {
    "papermill": {
     "duration": 0.022222,
     "end_time": "2024-02-04T18:01:33.404061",
     "exception": false,
     "start_time": "2024-02-04T18:01:33.381839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Expectation Maximization (EM)\n",
    "\n",
    "> Expectation Maximization (EM), denetimsiz Ã¶ÄŸrenme algoritmalarÄ±ndan biridir ve genellikle gizli deÄŸiÅŸkenlere sahip modellerin tahmininde kullanÄ±lÄ±r.\n",
    "> EM algoritmasÄ±, veri setindeki gÃ¶zlemlerin bir karÄ±ÅŸÄ±mÄ±nÄ± oluÅŸturan gizli bileÅŸenlerin (Ã¶rneÄŸin Gauss karÄ±ÅŸÄ±m modeli) parametrelerini tahmin etmek iÃ§in kullanÄ±lÄ±r.\n",
    "> EM algoritmasÄ±, iki ana adÄ±mdan oluÅŸur: Beklenti (Expectation) adÄ±mÄ± ve Maksimizasyon (Maximization) adÄ±mÄ±.\n",
    "> Beklenti adÄ±mÄ±nda, veri noktalarÄ± Ã¼zerindeki gizli deÄŸiÅŸkenlerin olasÄ± deÄŸerleri hesaplanÄ±r.\n",
    "> Maksimizasyon adÄ±mÄ±nda, veri seti Ã¼zerindeki gÃ¶zlemlerin parametreleri (Ã¶rneÄŸin, ortalama ve kovaryans matrisleri) maksimize edilir.\n",
    "> Bu iki adÄ±m iteratif olarak tekrarlanÄ±r ve EM algoritmasÄ±, veri setindeki gizli yapÄ±nÄ±n ve bileÅŸenlerin tahmin edilmesini saÄŸlar.\n",
    "\n",
    "**KullanÄ±lan Data Set ğŸ‘‡**\n",
    "\n",
    "https://www.kaggle.com/datasets/isatish/phishing-dataset-uci-ml-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "301def18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T18:01:33.460940Z",
     "iopub.status.busy": "2024-02-04T18:01:33.458838Z",
     "iopub.status.idle": "2024-02-04T18:01:33.890989Z",
     "shell.execute_reply": "2024-02-04T18:01:33.889696Z"
    },
    "papermill": {
     "duration": 0.468305,
     "end_time": "2024-02-04T18:01:33.894835",
     "exception": false,
     "start_time": "2024-02-04T18:01:33.426530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Accuracy: 0.24061510628674807\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Veri setini yÃ¼kleme ve Ã¶n iÅŸleme\n",
    "df = pd.read_csv('/kaggle/input/phishing-dataset-uci-ml-csv/uci-ml-phishing-dataset.csv')\n",
    "# BaÄŸÄ±mlÄ± deÄŸiÅŸken (y) ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) olarak ayÄ±rma\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Veri setini train ve test olarak ayÄ±rma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Expectation Maximization (EM)\n",
    "em = GaussianMixture(n_components=2) # Ä°ki sÄ±nÄ±f olduÄŸunu varsayalÄ±m\n",
    "em.fit(X_train)\n",
    "em_predictions = em.predict(X_test)\n",
    "em_accuracy = accuracy_score(y_test, em_predictions)\n",
    "\n",
    "# SonuÃ§larÄ± deÄŸerlendirme\n",
    "print(\"EM Accuracy:\", em_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 19,
     "sourceId": 420,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 228,
     "sourceId": 482,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 306,
     "sourceId": 666,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1216,
     "sourceId": 2184,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2374,
     "sourceId": 3987,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4458,
     "sourceId": 8204,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 84803,
     "sourceId": 196262,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 209295,
     "sourceId": 457469,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 515409,
     "sourceId": 960570,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 576697,
     "sourceId": 1043970,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 626341,
     "sourceId": 1116242,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 748772,
     "sourceId": 1295161,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 895414,
     "sourceId": 1519136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2214347,
     "sourceId": 3701254,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 90.280325,
   "end_time": "2024-02-04T18:01:36.383310",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-04T18:00:06.102985",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
